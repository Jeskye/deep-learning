{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rr00547872\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 31s 3us/step\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 364s 6ms/step - loss: 0.2606 - acc: 0.9206 - val_loss: 0.0594 - val_acc: 0.9806\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 343s 6ms/step - loss: 0.0933 - acc: 0.9719 - val_loss: 0.0405 - val_acc: 0.9871\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 339s 6ms/step - loss: 0.0671 - acc: 0.9794 - val_loss: 0.0382 - val_acc: 0.9870\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 318s 5ms/step - loss: 0.0548 - acc: 0.9831 - val_loss: 0.0335 - val_acc: 0.9886\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 323s 5ms/step - loss: 0.0478 - acc: 0.9858 - val_loss: 0.0354 - val_acc: 0.9880\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 344s 6ms/step - loss: 0.0427 - acc: 0.9870 - val_loss: 0.0297 - val_acc: 0.9908\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 330s 5ms/step - loss: 0.0385 - acc: 0.9885 - val_loss: 0.0281 - val_acc: 0.9905\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 329s 5ms/step - loss: 0.0339 - acc: 0.9891 - val_loss: 0.0282 - val_acc: 0.9906\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 336s 6ms/step - loss: 0.0328 - acc: 0.9900 - val_loss: 0.0280 - val_acc: 0.9910\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 293s 5ms/step - loss: 0.0304 - acc: 0.9905 - val_loss: 0.0258 - val_acc: 0.9910\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 268s 4ms/step - loss: 0.0296 - acc: 0.9910 - val_loss: 0.0276 - val_acc: 0.9918\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 265s 4ms/step - loss: 0.0267 - acc: 0.9917 - val_loss: 0.0304 - val_acc: 0.9916\n",
      "Test loss: 0.030436755853517298\n",
      "Test accuracy: 0.9916\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('model.h5')\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + r'C:\\Users\\rr00547872\\graphviz-2.38\\release\\bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_contour_thresh(img):\n",
    "    x, y, w, h = 0, 0, 300, 300\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (35, 35), 0)\n",
    "    ret, thresh1 = cv2.threshold(blur, 70, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    thresh1 = thresh1[y:y + h, x:x + w]\n",
    "    contours, hierarchy = cv2.findContours(thresh1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "    return img, contours, thresh1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6667.5\n",
      "6113.0\n",
      "115.0\n",
      "58.0\n",
      "396.5\n",
      "1802.5\n",
      "1329.5\n",
      "2197.5\n",
      "72.5\n",
      "508.5\n",
      "695.5\n",
      "2890.0\n",
      "541.0\n",
      "2181.5\n",
      "401.5\n",
      "13655.5\n",
      "185.0\n",
      "91.0\n",
      "141.0\n",
      "307.0\n",
      "1139.0\n",
      "57.5\n",
      "59.0\n",
      "19.0\n",
      "93.0\n",
      "117.5\n",
      "41.5\n",
      "95.0\n",
      "213.5\n",
      "94.5\n",
      "1007.0\n",
      "288.0\n",
      "200.0\n",
      "1023.5\n",
      "2437.0\n",
      "123.0\n",
      "1423.5\n",
      "1172.5\n",
      "256.0\n",
      "2138.0\n",
      "4551.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-44fe7ce57503>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Frame\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m27\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "cap = cv2.VideoCapture(0)\n",
    "Lower_green = np.array([110, 50, 50])\n",
    "Upper_green = np.array([130, 255, 255])\n",
    "pts = deque(maxlen=512)\n",
    "blackboard = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "digit = np.zeros((200, 200, 3), dtype=np.uint8)\n",
    "flag = 0\n",
    "ans2 = ''\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret, img = cap.read()\n",
    "    img = cv2.flip(img, 1)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    mask = cv2.inRange(hsv, Lower_green, Upper_green)\n",
    "    mask = cv2.erode(mask, kernel, iterations=2)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    # mask=cv2.morphologyEx(mask,cv2.MORPH_CLOSE,kernel)\n",
    "    mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "    res = cv2.bitwise_and(img, img, mask=mask)\n",
    "    cnts, heir = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "    center = None\n",
    "\n",
    "    if len(cnts) >= 1:\n",
    "        cnt = max(cnts, key=cv2.contourArea)\n",
    "        if cv2.contourArea(cnt) > 200:\n",
    "            ((x, y), radius) = cv2.minEnclosingCircle(cnt)\n",
    "            cv2.circle(img, (int(x), int(y)), int(radius), (0, 255, 255), 2)\n",
    "            cv2.circle(img, center, 5, (0, 0, 255), -1)\n",
    "            M = cv2.moments(cnt)\n",
    "            center = (int(M['m10'] / M['m00']), int(M['m01'] / M['m00']))\n",
    "            pts.appendleft(center)\n",
    "            for i in range(1, len(pts)):\n",
    "                if pts[i - 1] is None or pts[i] is None:\n",
    "                    continue\n",
    "                cv2.line(blackboard, pts[i - 1], pts[i], (255, 255, 255), 7)\n",
    "                cv2.line(img, pts[i - 1], pts[i], (0, 0, 255), 2)\n",
    "    elif len(cnts) == 0:\n",
    "        if len(pts) != []:\n",
    "            blackboard_gray = cv2.cvtColor(blackboard, cv2.COLOR_BGR2GRAY)\n",
    "            blur1 = cv2.medianBlur(blackboard_gray, 15)\n",
    "            blur1 = cv2.GaussianBlur(blur1, (5, 5), 0)\n",
    "            thresh1 = cv2.threshold(blur1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "            blackboard_cnts = cv2.findContours(thresh1.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[1]\n",
    "            if len(blackboard_cnts) >= 1:\n",
    "                cnt = max(blackboard_cnts, key=cv2.contourArea)\n",
    "                print(cv2.contourArea(cnt))\n",
    "                if cv2.contourArea(cnt) > 2000:\n",
    "                    x, y, w, h = cv2.boundingRect(cnt)\n",
    "                    digit = blackboard_gray[y:y + h, x:x + w]\n",
    "                    #newImage = cv2.resize(digit, (28, 28))\n",
    "                    image_read= (np.array(digit,'float'))\n",
    "                    im_read=cv2.resize(image_read,(28,28))\n",
    "                    img1 = im_read.reshape([1, 28, 28, 1])\n",
    "                    ans2 = model.predict(img1)\n",
    "                    \n",
    "                  \n",
    "        pts = deque(maxlen=512)\n",
    "        blackboard = np.zeros((480, 640, 3), dtype=np.uint8)\n",
    "        cv2.putText(img, \"Deep Network : \" + str(np.argmax(ans2)), (10, 410),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "   \n",
    "    cv2.imshow(\"Frame\", img)\n",
    "    k = cv2.waitKey(10)\n",
    "    if k == 27:\n",
    "        break\n",
    "    #cap.release()\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
